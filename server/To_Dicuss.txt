Resnet50 ELU:
596/596 [==============================] - 2119s 4s/step - loss: 1.1132 - accuracy: 0.7329 - val_loss: 0.4682 - val_accuracy: 0.8770
Epoch 2/5
596/596 [==============================] - 2125s 4s/step - loss: 0.3747 - accuracy: 0.9045 - val_loss: 0.3306 - val_accuracy: 0.9132
Epoch 3/5
596/596 [==============================] - 2168s 4s/step - loss: 0.2588 - accuracy: 0.9331 - val_loss: 0.2604 - val_accuracy: 0.9311
Epoch 4/5
596/596 [==============================] - 2182s 4s/step - loss: 0.2019 - accuracy: 0.9514 - val_loss: 0.2271 - val_accuracy: 0.9371
Epoch 5/5
596/596 [==============================] - 2098s 4s/step - loss: 0.1635 - accuracy: 0.9620 - val_loss: 0.1989 - val_accuracy: 0.9432

{'loss': 1.4281, 'grad_norm': 0.4898701310157776, 'learning_rate': 0.0009685534591194969, 'epoch': 0.31}
  3%|███▋                                                                                                                | 100/3180 [01:04<32:50,  1.56it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.9188013672828674, 'eval_rouge1': 0.13586079610814117, 'eval_rouge2': 0.0899581056940695, 'eval_rougeL': 0.13194269293087646, 'eval_rougeLsum': 0.13187385486784436, 'eval_runtime': 60.863, 'eval_samples_per_second': 10.433, 'eval_steps_per_second': 2.612, 'epoch': 0.31}                             
{'loss': 0.9423, 'grad_norm': 0.2419608235359192, 'learning_rate': 0.0009371069182389938, 'epoch': 0.63}                 
{'eval_loss': 0.8254468441009521, 'eval_rouge1': 0.13082843184554682, 'eval_rouge2': 0.08051349066686521, 'eval_rougeL': 0.12470847627288079, 'eval_rougeLsum': 0.12481860949493856, 'eval_runtime': 61.3005, 'eval_samples_per_second': 10.359, 'eval_steps_per_second': 2.594, 'epoch': 0.63}                           
{'loss': 0.885, 'grad_norm': 0.4087759256362915, 'learning_rate': 0.0009056603773584906, 'epoch': 0.94}                 
  9%|██████████▉                                                                                                         | 300/3180 [05:16<30:43,  1.56it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.7775501608848572, 'eval_rouge1': 0.13635550993237033, 'eval_rouge2': 0.08667044315543618, 'eval_rougeL': 0.12926723277408464, 'eval_rougeLsum': 0.12928026713369128, 'eval_runtime': 61.3359, 'eval_samples_per_second': 10.353, 'eval_steps_per_second': 2.592, 'epoch': 0.94}                           
{'loss': 0.8394, 'grad_norm': 0.22602073848247528, 'learning_rate': 0.0008742138364779874, 'epoch': 1.26}                 
{'eval_loss': 0.745311975479126, 'eval_rouge1': 0.1357730429444038, 'eval_rouge2': 0.0886923121997195, 'eval_rougeL': 0.13077970511369094, 'eval_rougeLsum': 0.1307000395334783, 'eval_runtime': 59.4152, 'eval_samples_per_second': 10.688, 'eval_steps_per_second': 2.676, 'epoch': 1.26}                               
{'loss': 0.7362, 'grad_norm': 0.23785056173801422, 'learning_rate': 0.0008427672955974843, 'epoch': 1.57}                 
 16%|██████████████████▏                                                                                                 | 500/3180 [09:27<28:34,  1.56it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.7227278351783752, 'eval_rouge1': 0.1298285143732703, 'eval_rouge2': 0.07826205954010357, 'eval_rougeL': 0.12217340665551651, 'eval_rougeLsum': 0.12214562375292584, 'eval_runtime': 60.3282, 'eval_samples_per_second': 10.526, 'eval_steps_per_second': 2.636, 'epoch': 1.57}                            
{'loss': 0.7791, 'grad_norm': 0.24255503714084625, 'learning_rate': 0.0008113207547169812, 'epoch': 1.88}                 
{'eval_loss': 0.7004613280296326, 'eval_rouge1': 0.1247448478072388, 'eval_rouge2': 0.06854848610462733, 'eval_rougeL': 0.11256825354942258, 'eval_rougeLsum': 0.11267000896404035, 'eval_runtime': 59.5983, 'eval_samples_per_second': 10.655, 'eval_steps_per_second': 2.668, 'epoch': 1.88}                            
{'loss': 0.7499, 'grad_norm': 0.24174687266349792, 'learning_rate': 0.0007798742138364781, 'epoch': 2.2}                 
 22%|█████████████████████████▌                                                                                          | 700/3180 [13:36<26:23,  1.57it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.6838296055793762, 'eval_rouge1': 0.13054694498123878, 'eval_rouge2': 0.07943808880164904, 'eval_rougeL': 0.12344660806217572, 'eval_rougeLsum': 0.1234857520132048, 'eval_runtime': 58.1301, 'eval_samples_per_second': 10.924, 'eval_steps_per_second': 2.735, 'epoch': 2.2}                             
{'loss': 0.7108, 'grad_norm': 0.22856047749519348, 'learning_rate': 0.0007484276729559748, 'epoch': 2.51}                 
{'eval_loss': 0.6686336398124695, 'eval_rouge1': 0.12759502043184046, 'eval_rouge2': 0.07491063838340489, 'eval_rougeL': 0.11879016378293136, 'eval_rougeLsum': 0.11891223146033442, 'eval_runtime': 60.2136, 'eval_samples_per_second': 10.546, 'eval_steps_per_second': 2.641, 'epoch': 2.51}                           
{'loss': 0.6959, 'grad_norm': 0.2225879579782486, 'learning_rate': 0.0007169811320754717, 'epoch': 2.83}                 
 28%|████████████████████████████████▊                                                                                   | 900/3180 [17:43<24:22,  1.56it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.65767502784729, 'eval_rouge1': 0.1302998151432074, 'eval_rouge2': 0.07588096003450631, 'eval_rougeL': 0.12022116610010897, 'eval_rougeLsum': 0.12021325770063335, 'eval_runtime': 60.1865, 'eval_samples_per_second': 10.551, 'eval_steps_per_second': 2.642, 'epoch': 2.83}                              
{'loss': 0.6912, 'grad_norm': 0.21049298346042633, 'learning_rate': 0.0006855345911949685, 'epoch': 3.14}                 
{'eval_loss': 0.6462303996086121, 'eval_rouge1': 0.13542862809540984, 'eval_rouge2': 0.08692336052764117, 'eval_rougeL': 0.12847641028368245, 'eval_rougeLsum': 0.1285450437333211, 'eval_runtime': 59.5251, 'eval_samples_per_second': 10.668, 'eval_steps_per_second': 2.671, 'epoch': 3.14}                            
{'loss': 0.6804, 'grad_norm': 0.23727859556674957, 'learning_rate': 0.0006540880503144654, 'epoch': 3.45}                 
 35%|███████████████████████████████████████▊                                                                           | 1100/3180 [21:53<22:11,  1.56it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.63834148645401, 'eval_rouge1': 0.1308582118588505, 'eval_rouge2': 0.07861192988458518, 'eval_rougeL': 0.12234851296572527, 'eval_rougeLsum': 0.12243702775966733, 'eval_runtime': 61.1198, 'eval_samples_per_second': 10.389, 'eval_steps_per_second': 2.601, 'epoch': 3.45}                              
{'loss': 0.6449, 'grad_norm': 0.22321629524230957, 'learning_rate': 0.0006226415094339623, 'epoch': 3.77}                 
{'eval_loss': 0.628957986831665, 'eval_rouge1': 0.13222237063320416, 'eval_rouge2': 0.08105018629378763, 'eval_rougeL': 0.12423413806360727, 'eval_rougeLsum': 0.1242588052252524, 'eval_runtime': 59.4522, 'eval_samples_per_second': 10.681, 'eval_steps_per_second': 2.674, 'epoch': 3.77}                             
{'loss': 0.6456, 'grad_norm': 0.18630461394786835, 'learning_rate': 0.0005911949685534591, 'epoch': 4.08}                 
 41%|███████████████████████████████████████████████                                                                    | 1300/3180 [674, 'epoch': 3.77}
{'loss': 0.6456, 'grad_norm': 0.18630461394786835, 'learning_rate': 0.0005911949685534591, 'epoch': 4.08}
 41%|███████████████████████████████████████████████                                                                    | 1300/3180 [26:02<20:03,  1.56it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.6266741752624512, 'eval_rouge1': 0.13227175700399868, 'eval_rouge2': 0.0823958338619131, 'eval_rougeL': 0.12633105025200236, 'eval_rougeLsum': 0.12635254701605028, 'eval_runtime': 59.2501, 'eval_samples_per_second': 10.717, 'eval_steps_per_second': 2.684, 'epoch': 4.08}
{'loss': 0.6275, 'grad_norm': 0.27005910873413086, 'learning_rate': 0.000559748427672956, 'epoch': 4.4}
{'eval_loss': 0.6173889636993408, 'eval_rouge1': 0.13393717381358333, 'eval_rouge2': 0.08080612049503144, 'eval_rougeL': 0.12404208082356113, 'eval_rougeLsum': 0.1240081021484718, 'eval_runtime': 61.7107, 'eval_samples_per_second': 10.29, 'eval_steps_per_second': 2.577, 'epoch': 4.4}
{'loss': 0.6264, 'grad_norm': 0.17831861972808838, 'learning_rate': 0.0005283018867924528, 'epoch': 4.71}
 47%|██████████████████████████████████████████████████████▏                                                            | 1500/3180 [30:13<17:54,  1.56it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(

 25%|████████████████████████████▉                                                                                         | 39/159 [00:10<00:34,  3.49it/s]
 25%|███████████████████████▋                                                                      | 40/159 [00:10<00:34,  3.43it/s]        
                                                                                                                                            
{'eval_loss': 0.6098368167877197, 'eval_rouge1': 0.12952005146249404, 'eval_rouge2': 0.07499350596793836, 'eval_rougeL': 0.12157404539253895, 'eval_rougeLsum': 0.1215394925706116, 'eval_runtime': 60.6944, 'eval_samples_per_second': 10.462, 'eval_steps_per_second': 2.62, 'epoch': 4.71}
{'loss': 0.6171, 'grad_norm': 0.2576424181461334, 'learning_rate': 0.0004968553459119497, 'epoch': 5.02}                                    
{'eval_loss': 0.6053285598754883, 'eval_rouge1': 0.1303616135982255, 'eval_rouge2': 0.07857240748183694, 'eval_rougeL': 0.12242796901993072, 'eval_rougeLsum': 0.12248677380029518, 'eval_runtime': 58.9395, 'eval_samples_per_second': 10.774, 'eval_steps_per_second': 2.698, 'epoch': 5.02}
{'loss': 0.5857, 'grad_norm': 0.24397549033164978, 'learning_rate': 0.00046540880503144656, 'epoch': 5.34}                                  
 53%|████████████████████████████████████████████████████▍                                             | 1700/3180 [34:23<15:46,  1.56it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.601628839969635, 'eval_rouge1': 0.13281835317117655, 'eval_rouge2': 0.08104022500049646, 'eval_rougeL': 0.12487032894963664, 'eval_rougeLsum': 0.1249899110547405, 'eval_runtime': 61.7285, 'eval_samples_per_second': 10.287, 'eval_steps_per_second': 2.576, 'epoch': 5.34}
{'loss': 0.6028, 'grad_norm': 0.2692405879497528, 'learning_rate': 0.00043396226415094345, 'epoch': 5.65}                                   
{'eval_loss': 0.5961265563964844, 'eval_rouge1': 0.13041267830292885, 'eval_rouge2': 0.07947782267862313, 'eval_rougeL': 0.12240120261332957, 'eval_rougeLsum': 0.12241609153767886, 'eval_runtime': 61.4966, 'eval_samples_per_second': 10.326, 'eval_steps_per_second': 2.586, 'epoch': 5.65}
{'loss': 0.5936, 'grad_norm': 0.2234571874141693, 'learning_rate': 0.0004025157232704403, 'epoch': 5.97}                                    
 60%|██████████████████████████████████████████████████████████▌                                       | 1900/3180 [38:37<13:44,  1.55it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.5903766751289368, 'eval_rouge1': 0.12985238333196653, 'eval_rouge2': 0.07602385996957856, 'eval_rougeL': 0.12125735514240207, 'eval_rougeLsum': 0.12128850547102252, 'eval_runtime': 60.1693, 'eval_samples_per_second': 10.554, 'eval_steps_per_second': 2.643, 'epoch': 5.97}
{'loss': 0.5833, 'grad_norm': 0.2378339022397995, 'learning_rate': 0.0003710691823899371, 'epoch': 6.28}                                    
{'eval_loss': 0.588976263999939, 'eval_rouge1': 0.12902716324992686, 'eval_rouge2': 0.07589706137150046, 'eval_rougeL': 0.12139452008186563, 'eval_rougeLsum': 0.12141979127354438, 'eval_runtime': 63.1499, 'eval_samples_per_second': 10.055, 'eval_steps_per_second': 2.518, 'epoch': 6.28}
{'loss': 0.5772, 'grad_norm': 0.2731660008430481, 'learning_rate': 0.00033962264150943393, 'epoch': 6.59}                                   
 66%|████████████████████████████████████████████████████████████████▋                                 | 2100/3180 [42:51<11:40,  1.54it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.5858327746391296, 'eval_rouge1': 0.13056712294768616, 'eval_rouge2': 0.07776629762748255, 'eval_rougeL': 0.12211861801791532, 'eval_rougeLsum': 0.1221957050452018, 'eval_runtime': 60.9418, 'eval_samples_per_second': 10.42, 'eval_steps_per_second': 2.609, 'epoch': 6.59}
{'loss': 0.5757, 'grad_norm': 0.2380443811416626, 'learning_rate': 0.0003081761006289308, 'epoch': 6.91}                                    
{'eval_loss': 0.5798869729042053, 'eval_rouge1': 0.12886144680302697, 'eval_rouge2': 0.07621509478472435, 'eval_rougeL': 0.12046387454355459, 'eval_rougeLsum': 0.12053751719027264, 'eval_runtime': 60.6491, 'eval_samples_per_second': 10.47, 'eval_steps_per_second': 2.622, 'epoch': 6.91}
{'loss': 0.5511, 'grad_norm': 0.28158000111579895, 'learning_rate': 0.00027672955974842765, 'epoch': 7.22}                                  
 72%|██████████████████████████████████████████████████████████████████████▉                           | 2300/3180 [47:03<09:33,  1.53it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.5789470672607422, 'eval_rouge1': 0.12896459017127493, 'eval_rouge2': 0.07666060285209118, 'eval_rougeL': 0.12128596546089156, 'eval_rougeLsum': 0.12135410311981967, 'eval_runtime': 61.8181, 'eval_samples_per_second': 10.272, 'eval_steps_per_second': 2.572, 'epoch': 7.22}
{'loss': 0.5431, 'grad_norm': 0.22011305391788483, 'learning_rate': 0.00024528301886792453, 'epoch': 7.54}                                  
{'eval_loss': 0.5768689513206482, 'eval_rouge1': 0.12901878036794304, 'eval_rouge2': 0.07588490891507435, 'eval_rougeL': 0.1206609261808932, 'eval_rougeLsum': 0.12065273766689003, 'eval_runtime': 59.9832, 'eval_samples_per_second': 10.586, 'eval_steps_per_second': 2.651, 'epoch': 7.54}
{'loss': 0.5614, 'grad_norm': 0.28907814621925354, 'learning_rate': 0.0002138364779874214, 'epoch': 7.85}                                   
 79%|█████████████████████████████████████████████████████████████████████████████                     | 2500/3180 [51:15<07:20,  1.54it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.5735718607902527, 'eval_rouge1': 0.12858187589346748, 'eval_rouge2': 0.0755149683466243, 'eval_rougeL': 0.12017434112852572, 'eval_rougeLsum': 0.12025783380373752, 'eval_runtime': 61.6328, 'eval_samples_per_second': 10.303, 'eval_steps_per_second': 2.58, 'epoch': 7.85}
{'loss': 0.5296, 'grad_norm': 0.28862306475639343, 'learning_rate': 0.00018238993710691822, 'epoch': 8.16}                                  
{'eval_loss': 0.5740135312080383, 'eval_rouge1': 0.1284030576823006, 'eval_rouge2': 0.07657672080576663, 'eval_rougeL': 0.12041954662006932, 'eval_rougeLsum': 0.12044799481805671, 'eval_runtime': 60.8309, 'eval_samples_per_second': 10.439, 'eval_steps_per_second': 2.614, 'epoch': 8.16}
{'loss': 0.5479, 'grad_norm': 0.22214975953102112, 'learning_rate': 0.0001509433962264151, 'epoch': 8.48}                                   
 85%|███████████████████████████████████████████████████████████████████████████████████▏              | 2700/3180 [55:27<05:10,  1.54it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.5707133412361145, 'eval_rouge1': 0.13055898619335954, 'eval_rouge2': 0.07841670271735839, 'eval_rougeL': 0.12255701686626601, 'eval_rougeLsum': 0.12257312709598661, 'eval_runtime': 59.7255, 'eval_samples_per_second': 10.632, 'eval_steps_per_second': 2.662, 'epoch': 8.48}
{'loss': 0.5534, 'grad_norm': 0.19150766730308533, 'learning_rate': 0.00011949685534591196, 'epoch': 8.79}                                  
{'eval_loss': 0.5676649808883667, 'eval_rouge1': 0.1292713348651352, 'eval_rouge2': 0.07730510518212375, 'eval_rougeL': 0.1213753127095401, 'eval_rougeLsum': 0.12140284655952724, 'eval_runtime': 61.0998, 'eval_samples_per_second': 10.393, 'eval_steps_per_second': 2.602, 'epoch': 8.79}
{'loss': 0.5424, 'grad_norm': 0.2433236837387085, 'learning_rate': 8.80503144654088e-05, 'epoch': 9.11}                                     
 91%|█████████████████████████████████████████████████████████████████████████████████████████▎        | 2900/3180 [59:38<03:01,  1.54it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.5666633248329163, 'eval_rouge1': 0.12831941684614842, 'eval_rouge2': 0.07473645700530866, 'eval_rougeL': 0.11927286760764741, 'eval_rougeLsum': 0.11930736898815952, 'eval_runtime': 60.6394, 'eval_samples_per_second': 10.472, 'eval_steps_per_second': 2.622, 'epoch': 9.11}
{'loss': 0.5456, 'grad_norm': 0.3262537717819214, 'learning_rate': 5.660377358490566e-05, 'epoch': 9.42}                                    
{'eval_loss': 0.5656658411026001, 'eval_rouge1': 0.12808960751049242, 'eval_rouge2': 0.07470113815922981, 'eval_rougeL': 0.11987757032276362, 'eval_rougeLsum': 0.11986385292258975, 'eval_runtime': 59.4843, 'eval_samples_per_second': 10.675, 'eval_steps_per_second': 2.673, 'epoch': 9.42}
{'loss': 0.5216, 'grad_norm': 0.23198379576206207, 'learning_rate': 2.5157232704402517e-05, 'epoch': 9.73}                                  
 97%|█████████████████████████████████████████████████████████████████████████████████████████████▌  | 3100/3180 [1:03:49<00:51,  1.55it/s]C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\transformers\generation\utils.py:1178: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
{'eval_loss': 0.5651276707649231, 'eval_rouge1': 0.1290722356145806, 'eval_rouge2': 0.0765615179026112, 'eval_rougeL': 0.12120843408478583, 'eval_rougeLsum': 0.12116188283790363, 'eval_runtime': 62.0429, 'eval_samples_per_second': 10.235, 'eval_steps_per_second': 2.563, 'epoch': 9.73}
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 3180/3180 [1:05:43<00:00,  1.55it/s]There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].
{'train_runtime': 3943.4724, 'train_samples_per_second': 6.454, 'train_steps_per_second': 0.806, 'train_loss': 0.6643258280724099, 'epoch': 9.98}
100%|████████████████████████████████████████████████████████████████████████████████████████████████| 3180/3180 [1:05:43<00:00,  1.24s/it

Cake Datasets: 
https://github.com/josephrmartinez/recipe-dataset/blob/main/13k-recipes.csv
https://github.com/sandhaka/recipes-dataset/blob/main/dishes.csv

Roboflow Datasets: 
1. 
# Detection_of_ingr > 2023-05-24 11:05pm
https://universe.roboflow.com/fruits-qrswm/detection_of_ingr

Detection_of_ingr - v3 2023-05-24 11:05pm
==============================

This dataset was exported via roboflow.com on January 3, 2024 at 10:25 AM GMT

2.
# Every-Ingredient-2 > 2023-05-01 1:47pm
https://universe.roboflow.com/vegetableimages/every-ingredient-2
Every-Ingredient-2 - v2 2023-05-01 1:47pm
==============================

This dataset was exported via roboflow.com on January 3, 2024 at 8:12 AM GMT

3.
# Food ingredient recognition > 2022-02-24 1:40pm
https://universe.roboflow.com/thanh-huy-phan/food-ingredient-recognition
Food ingredient recognition - v4 2022-02-24 1:40pm
==============================

This dataset was exported via roboflow.com on March 31, 2023 at 12:12 AM GMT

4.
# FOOD-INGREDIENTS dataset > 2023-10-06 11:10pm
https://universe.roboflow.com/food-recipe-ingredient-images-0gnku/food-ingredients-dataset
FOOD-INGREDIENTS dataset - v4 2023-10-06 11:10pm
==============================

This dataset was exported via roboflow.com on October 18, 2023 at 5:20 PM GMT

5.
# IngredientDetectorMerged > 2022-10-10 8:46pm
https://universe.roboflow.com/tsiisccds/ingredientdetectormerged'
IngredientDetectorMerged - v6 2022-10-10 8:46pm
==============================

This dataset was exported via roboflow.com on January 3, 2024 at 8:53 AM GMT

6.
# IngredientDetector > 2022-10-06 2:24am
https://universe.roboflow.com/tsiisccds/ingredientdetector
IngredientDetector - v4 2022-10-06 2:24am
==============================

This dataset was exported via roboflow.com on January 3, 2024 at 9:00 AM GMT

7.
# Ingredients Detection > 2023-07-08 6:04pm
https://universe.roboflow.com/dappuu/ingredients-detection-ze16s
Ingredients Detection - v20 2023-07-08 6:04pm
==============================

This dataset was exported via roboflow.com on January 3, 2024 at 8:35 AM GMT

8.
# ingredients > 2023-09-26 11:41am
https://universe.roboflow.com/object-detection-f8udo/ingredients-hbvsw
ingredients - v1 2023-09-26 11:41am
==============================

This dataset was exported via roboflow.com on December 16, 2023 at 5:31 PM GMT

9.
https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition
KRITIK SETH, 2022, Fruits and Vegetables Image Recognition Dataset
Fruit and Vegetable Images for Object Recognition

10.
# phanloaihat > 2023-03-14 11:30pm
https://universe.roboflow.com/xu-ly-anh/phanloaihat
phanloaihat - v2 2023-03-14 11:30pm
==============================

This dataset was exported via roboflow.com on November 20, 2023 at 1:29 AM GMT


Meeting with Tissa 4: 

1. 
Abstract - overview of problem is 3 lines
3 lines of what i have done
3 lines of results
Conclusion 1 line: impact of this model 
Summary of the entire project / half page 

introduction : indepth
Layout background and link to literature / survey papers 
Addres what others have done: their limitaitions and identify their gaps
Propose what you are going to do 
: introduce aims and objectives 
Say what yr going to do in the subsequent chapters 
2 to 3 pages 
Methods 1 and 2 ….. Chapter 3 more detail on method is better


Refer datasets: 
List original. Ref to original down to source. 
How did you modify and what part are you using

Reference dataset considered: 
Ref compared dataset

Dataset: 
Mention also contains crab cakes. 
Justify why. The word cake there. Doesnt affect the overall process
This also in another way imrpove the learning process of the model. False negative 

Medium: 
Can cite 
Cite as a website 

Consider methodology: 
Overview what is available and the decision to use the one chosen .
Pros and cons, hence i chosen xxx
In depth of xxx. 
If chose y previously, also explain y 
Overall ones just explain briefly 

Watershed has limitation xxx. This is sovled by intellient scissors, hence it was chosen. 
Overview for watershed but in depth to intellgent scissors .


2. Dataset images: only from stock photos or google images / shoppee 
Comparing models is critical analysis: 
methodology and results

Dataset stock photo: 
Not enough photos 
Individually allowed ro use or not 

3. Storage
Reference his github 
Resources for htis available from xxxxx
Model in final report: 
Why was this model used but this one used all the way to findl 
Final reprot describe process of trial and error and addresses weakensses of eliminated models and hwy it was eliminated until the final one chosen .

 

Todo: 
1. remove ingredients from dataset to clean up the ingredients expected 
2. add title to dataset

Report Writing: 
1. 70 20 10 split: 
    https://arxiv.org/ftp/arxiv/papers/2203/2203.06721.pdf
    https://www.mdpi.com/1424-8220/22/21/8290

2. Test Results using confusion matrix:

Experiments: 
    1. 702010 Train Valid Test with Base code + 10 epochs
    Training generator samples: 19072
    Validation generator samples: 5459
    Epoch 1/10
    113/596 [====>.........................] - ETA: 1:11 - loss: 4.9065 - accuracy: 0.0993C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
    warnings.warn(
    596/596 [==============================] - 114s 189ms/step - loss: 2.9401 - accuracy: 0.3411 - val_loss: 1.8055 - val_accuracy: 0.5360
    Epoch 2/10
    596/596 [==============================] - 111s 185ms/step - loss: 1.4528 - accuracy: 0.6108 - val_loss: 1.2951 - val_accuracy: 0.6432
    Epoch 3/10
    596/596 [==============================] - 111s 186ms/step - loss: 1.0616 - accuracy: 0.7037 - val_loss: 1.0875 - val_accuracy: 0.6945
    Epoch 4/10
    596/596 [==============================] - 111s 187ms/step - loss: 0.8565 - accuracy: 0.7559 - val_loss: 0.9329 - val_accuracy: 0.7327
    Epoch 5/10
    596/596 [==============================] - 111s 186ms/step - loss: 0.7154 - accuracy: 0.7913 - val_loss: 0.8343 - val_accuracy: 0.7592
    Epoch 6/10
    596/596 [==============================] - 111s 185ms/step - loss: 0.6075 - accuracy: 0.8248 - val_loss: 0.7703 - val_accuracy: 0.7785
    Epoch 7/10
    596/596 [==============================] - 110s 185ms/step - loss: 0.5353 - accuracy: 0.8406 - val_loss: 0.7325 - val_accuracy: 0.7857
    Epoch 8/10
    596/596 [==============================] - 110s 185ms/step - loss: 0.4747 - accuracy: 0.8594 - val_loss: 0.6874 - val_accuracy: 0.8020
    Epoch 9/10
    596/596 [==============================] - 110s 184ms/step - loss: 0.4304 - accuracy: 0.8764 - val_loss: 0.6573 - val_accuracy: 0.8123
    Epoch 10/10
    596/596 [==============================] - 112s 188ms/step - loss: 0.3974 - accuracy: 0.8834 - val_loss: 0.6256 - val_accuracy: 0.8263
        
    2. 702010 Train Valid Test with current code + 10 epochs
    Training generator samples: 19072
    Validation generator samples: 5459
    Epoch 1/10
    146/596 [======>.......................] - ETA: 1:10 - loss: 2.7881 - accuracy: 0.3739C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
    warnings.warn(
    596/596 [==============================] - 115s 190ms/step - loss: 1.7035 - accuracy: 0.5704 - val_loss: 1.0938 - val_accuracy: 0.6853
    Epoch 2/10
    596/596 [==============================] - 111s 186ms/step - loss: 0.8243 - accuracy: 0.7581 - val_loss: 0.8276 - val_accuracy: 0.7636
    Epoch 3/10
    596/596 [==============================] - 111s 186ms/step - loss: 0.5931 - accuracy: 0.8244 - val_loss: 0.7367 - val_accuracy: 0.7917
    Epoch 4/10
    596/596 [==============================] - 111s 186ms/step - loss: 0.4792 - accuracy: 0.8545 - val_loss: 0.6462 - val_accuracy: 0.8094
    Epoch 5/10
    596/596 [==============================] - 114s 192ms/step - loss: 0.3932 - accuracy: 0.8820 - val_loss: 0.5807 - val_accuracy: 0.8300
    Epoch 6/10
    596/596 [==============================] - 128s 215ms/step - loss: 0.3399 - accuracy: 0.8964 - val_loss: 0.5614 - val_accuracy: 0.8368
    Epoch 7/10
    596/596 [==============================] - 137s 230ms/step - loss: 0.2928 - accuracy: 0.9125 - val_loss: 0.5302 - val_accuracy: 0.8471
    Epoch 8/10
    596/596 [==============================] - 118s 198ms/step - loss: 0.2589 - accuracy: 0.9215 - val_loss: 0.5174 - val_accuracy: 0.8570
    Epoch 9/10
    596/596 [==============================] - 111s 185ms/step - loss: 0.2319 - accuracy: 0.9299 - val_loss: 0.5059 - val_accuracy: 0.8592
    Epoch 10/10
    596/596 [==============================] - 111s 186ms/step - loss: 0.2116 - accuracy: 0.9364 - val_loss: 0.4869 - val_accuracy: 0.8658

    3. 701020 Train Valid Test with Base code + 10 epochs
    Training generator samples: 19072
    Validation generator samples: 2729
    Epoch 1/10
    29/596 [>.............................] - ETA: 1:33 - loss: 6.1683 - accuracy: 0.0291C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
    warnings.warn(
    596/596 [==============================] - 109s 180ms/step - loss: 2.8715 - accuracy: 0.3539 - val_loss: 1.7887 - val_accuracy: 0.5309
    Epoch 2/10
    596/596 [==============================] - 101s 170ms/step - loss: 1.4437 - accuracy: 0.6138 - val_loss: 1.2761 - val_accuracy: 0.6507
    Epoch 3/10
    596/596 [==============================] - 100s 168ms/step - loss: 1.0566 - accuracy: 0.7071 - val_loss: 1.0512 - val_accuracy: 0.7040
    Epoch 4/10
    596/596 [==============================] - 101s 169ms/step - loss: 0.8466 - accuracy: 0.7568 - val_loss: 0.9360 - val_accuracy: 0.7371
    Epoch 5/10
    596/596 [==============================] - 100s 168ms/step - loss: 0.7134 - accuracy: 0.7917 - val_loss: 0.8503 - val_accuracy: 0.7673
    Epoch 6/10
    596/596 [==============================] - 103s 172ms/step - loss: 0.6155 - accuracy: 0.8178 - val_loss: 0.7938 - val_accuracy: 0.7805
    Epoch 7/10
    596/596 [==============================] - 102s 171ms/step - loss: 0.5366 - accuracy: 0.8417 - val_loss: 0.7223 - val_accuracy: 0.7956
    Epoch 8/10
    596/596 [==============================] - 103s 173ms/step - loss: 0.4717 - accuracy: 0.8605 - val_loss: 0.6850 - val_accuracy: 0.8118
    Epoch 9/10
    596/596 [==============================] - 101s 169ms/step - loss: 0.4347 - accuracy: 0.8724 - val_loss: 0.6565 - val_accuracy: 0.8180
    Epoch 10/10
    596/596 [==============================] - 102s 171ms/step - loss: 0.3906 - accuracy: 0.8839 - val_loss: 0.6494 - val_accuracy: 0.8202

    4. 701020 Train Valid Test with current code + 10 epochs
    Training generator samples: 19072
    Validation generator samples: 2729
    Epoch 1/10
    139/596 [=====>........................] - ETA: 1:10 - loss: 2.9405 - accuracy: 0.3604C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
    warnings.warn(
    596/596 [==============================] - 105s 173ms/step - loss: 1.7479 - accuracy: 0.5627 - val_loss: 1.1515 - val_accuracy: 0.6695
    Epoch 2/10
    596/596 [==============================] - 102s 172ms/step - loss: 0.8433 - accuracy: 0.7515 - val_loss: 0.8804 - val_accuracy: 0.7452
    Epoch 3/10
    596/596 [==============================] - 103s 173ms/step - loss: 0.6112 - accuracy: 0.8174 - val_loss: 0.7207 - val_accuracy: 0.7926
    Epoch 4/10
    596/596 [==============================] - 103s 172ms/step - loss: 0.4930 - accuracy: 0.8496 - val_loss: 0.6823 - val_accuracy: 0.8077
    Epoch 5/10
    596/596 [==============================] - 102s 171ms/step - loss: 0.4080 - accuracy: 0.8758 - val_loss: 0.6194 - val_accuracy: 0.8313
    Epoch 6/10
    596/596 [==============================] - 102s 171ms/step - loss: 0.3429 - accuracy: 0.8960 - val_loss: 0.5848 - val_accuracy: 0.8397
    Epoch 7/10
    596/596 [==============================] - 102s 172ms/step - loss: 0.2980 - accuracy: 0.9092 - val_loss: 0.5553 - val_accuracy: 0.8500
    Epoch 8/10
    596/596 [==============================] - 102s 171ms/step - loss: 0.2674 - accuracy: 0.9191 - val_loss: 0.5508 - val_accuracy: 0.8607
    Epoch 9/10
    596/596 [==============================] - 102s 171ms/step - loss: 0.2374 - accuracy: 0.9279 - val_loss: 0.5373 - val_accuracy: 0.8588
    Epoch 10/10
    596/596 [==============================] - 103s 172ms/step - loss: 0.2184 - accuracy: 0.9337 - val_loss: 0.5012 - val_accuracy: 0.8629

    5. 702010 Train Valid Test with current code + 5 epochs + 224 224 size


    2. resnet50 current vs resnet50 base: 
    current: 
    Epoch 1/5
    56/596 [=>............................] - ETA: 6:45 - loss: 3.5231 - accuracy: 0.2288C:\Users\miku\AppData\Local\Programs\Python\Python310\lib\site-packages\PIL\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
    warnings.warn(
    596/596 [==============================] - 593s 991ms/step - loss: 1.2762 - accuracy: 0.7090 - val_loss: 0.4972 - val_accuracy: 0.8754
    Epoch 2/5
    596/596 [==============================] - 588s 987ms/step - loss: 0.4057 - accuracy: 0.8939 - val_loss: 0.3257 - val_accuracy: 0.9132
    Epoch 3/5
    596/596 [==============================] - 591s 991ms/step - loss: 0.2807 - accuracy: 0.9277 - val_loss: 0.2680 - val_accuracy: 0.9285
    Epoch 4/5
    596/596 [==============================] - 593s 996ms/step - loss: 0.2117 - accuracy: 0.9487 - val_loss: 0.2269 - val_accuracy: 0.9368
    Epoch 5/5
    596/596 [==============================] - 592s 994ms/step - loss: 0.1721 - accuracy: 0.9603 - val_loss: 0.2018 - val_accuracy: 0.9436



19/3/2024: 
Test Results for T5 small:
TEST 1: Ingredients + measurements
Text:  2 1/2 cups all-purpose flour', '1/2 cup packed brown sugar', '1/4 cup butter', '1/2 cup chopped walnuts', '1 cup white sugar', '1 teaspoon baking soda', '1 teaspoon salt', '1/2 cup shortening', '2 eggs', '1 cup buttermilk', '1 teaspoon vanilla extract', '1 cup semisweet chocolate chip
Output:  tensor([[    0,   276, 22777,  4836,    12, 10239,  4526,   377,  4077,  3072,
          4526,   205,   137,  3796, 14608,    11,  7055,     3,     9,   668,
           226,  2368,  5913,  2131,     5,    31,     6,     3,    31,  1570,
             3,     9,   508,  3047,     6,  2153,   544,     8,  7055,     6,
          4216,  2656,     6, 13004,  4119,  4194,     6, 22962,     7,     6,
           872,  2656,     6,  6506, 12495,    11,  3136,     5,  2821,  5915,
             5,    31,     6,     3,    31,  1570,     3,     9,   508,  3047,
             6,  3022,   544,     8,   710,    35,    53,    11,  5875,   552,
           659,    11, 25155,     5, 14117,    16,     8,  4194, 25751,    11,
         13478,     5, 14117,    16,     8,  7055,  4989, 13902,   120,    28,
             8,  3711,  8852,     5,  1474, 15839,   139,  2657,  2131,     5,
            31,     6,     3,    31,   279,     9,  1050,    16,     8,   554,
            88,   920,  4836,    21,  3097,    12,  1283,   676,     6,    42,
           552,     3,     9,  6290, 17967,     3, 19435,   139,     8,  1530,
            13,     8,  4340,   639,    91,  1349,     5,  1563,  1633,    16,
          2131,    21,   335,   676,     6,   258,   919,    91,  2400,     3,
             9,  4107,  7782,    11,  1633,  1551,     1]])


Decoded output:  Preheat oven to 350 degrees F (175 degrees C). Grease and flour a 9x13 inch pan.', 'In a large bowl, mix together the flour, brown sugar, 1/4 cup butter, walnuts, white sugar, baking soda and salt. Set aside.', 'In a large bowl, cream together the shortening and eggs until light and fluffy. Beat in the buttermilk and vanilla. Beat in the flour mixture alternately with the chocolate chips. Pour batter into prepared pan.', 'Bake in the preheated oven for 35 to 40 minutes, or until a toothpick inserted into the center of the cake comes out clean. Let cool in pan for 10 minutes, then turn out onto a wire rack and cool completely


Prediction:  Preheat oven to 350 degrees F (175 degrees C).


TEST 2: no measurements + many ingredients
Text:   brown sugar, raisins, water, shortening, baking soda, salt, ground cinnamon, nutmeg, cloves, flour
Output:  tensor([[    0,   276, 22777,  4836,    12, 10239,  4526,   377,  4077,  3072,
          4526,   205,   137,  3796, 14608,    11,  7055,     3,     9,   335,
          5913,  8017,  2131,     5,   180,    99,    17,   544,     8,  7055,
             6,  2656,     6, 31078,     6,   387,     6,   710,    35,    53,
             6,  6506, 12495,     6,  3136,     6, 18684,     6,     3,  4796,
           526,   122,     6,    11, 27577,     7,     5,  2821,  5915,     5,
             1]])


Decoded output:  Preheat oven to 350 degrees F (175 degrees C). Grease and flour a 10 inch tube pan. Sift together the flour, sugar, raisins, water, shortening, baking soda, salt, cinnamon, nutmeg, and cloves. Set aside.


Prediction:  Preheat oven to 350 degrees F (175 degrees C).


TEST 3: no measurements + few ingredients
Text:  flour, yeast, apple, banana
Output:  tensor([[    0,   276, 22777,  4836,    12, 10239,  4526,   377,  4077,  3072,
          4526,   205,   137,  3796, 14608,    11,  7055,     3,     9,   668,
           226,  2368,  5913,  2131,     5,   180,    99,    17,   544,     8,
          7055,     6, 17937,     6,  8947,    11, 13634,     7,     5,  2821,
          5915,     5,     1]])


Decoded output:  Preheat oven to 350 degrees F (175 degrees C). Grease and flour a 9x13 inch pan. Sift together the flour, yeast, apple and bananas. Set aside.


Prediction:  Preheat oven to 350 degrees F (175 degrees C).


TEST 4
Predicted text:  Preheat oven to 350 degrees F (175 degrees C).

20/3/24: 
Satisfactory results:
TEST 1: Ingredients + measurements
Text:  '2 1/2 cups whole wheat pastry or spelt flour', '1 tablespoon baking powder', '2 teaspoons baking soda', '1 tablespoon cinnamon', '1/2 teaspoon ground ginger', '1/2 teaspoon ground cloves or allspice', '1 cup dark agave nectar or pure maple syrup, or half of each', '1 cup applesauce', '1/2 cup safflower oil', '2 teaspoons vanilla extract', '1/2 cup dark or golden raisins', '1/4 cup sliced almonds'
Output:  tensor([[    0,  2233,    10,  2184,  7348,   565, 25727, 17031,  7943,    10,
             3,    31,   345, 22777,  4836,    12, 10239,  4526,   377,  4077,
          3072,  4526,   205,   137,  3796, 14608,    11,  7055,     3,     9,
           335,  5913,  6100,    26,    17,  2131,     5,   180,    99,    17,
           544,     8,   829, 13221, 20772,  7055,     6,  6506,  4926,     6,
          6506, 12495,     6, 18684,     6, 15698,     6, 27577,     7,     6,
            11,    66,     7,  6174,    15,     5,  2821,  5915,     5,    31,
             6,     3,    31,  1570,     3,     9,   508,  3047,     6, 14242,
           544,     8,     3,  4711,   162,  9705,  2046,     6, 22007, 15928,
             6, 16981,   402,   565,     6,     3,     7,     9,    89, 14923,
          1043,     6, 13478,     6,    11, 31078,     5, 14117,    16,     8,
          7055,  4989, 13902,   120,    28,     8,  2192,  3018,     6,  1849,
            11,  7784,    28,  7055,  4989,     5,  1474, 15839,   139,  2657,
          2131,     5,    31,     6,     3,    31,   279,     9,  1050,    16,
             8,   554,    88,   920,  4836,    21,   943,    12,  1640,   676,
             6,    42,   552,     3,     9,  6290, 17967,     3, 19435,   139,
             8,  1530,    13,     8,  4340,   639,    91,  1349,     5,  1563,
          1633,    16,  2131,    21,   335,   676,     6,   258,   919,    91,
          2400,     3,     9,  4107,  7782,    11,  1633,  1551,     5,    31,
             1]])


Decoded output:  title: Applesauce Spice Cake directions: 'Preheat oven to 350 degrees F (175 degrees C). Grease and flour a 10 inch Bundt pan. Sift together the whole wheat pastry flour, baking powder, baking soda, cinnamon, ginger, cloves, and allspice. Set aside.', 'In a large bowl, whisk together the agave nectar, maple syrup, applesauce, safflower oil, vanilla, and raisins. Beat in the flour mixture alternately with the dry ingredients, beginning and ending with flour mixture. Pour batter into prepared pan.', 'Bake in the preheated oven for 50 to 60 minutes, or until a toothpick inserted into the center of the cake comes out clean. Let cool in pan for 10 minutes, then turn out onto a wire rack and cool completely.'


Prediction:  ["title: Applesauce Spice Cake directions: 'Preheat oven to 350 degrees F (175 degrees C).", 'Grease and flour a 10 inch Bundt pan.', 'Sift together the whole wheat pastry flour, baking powder, baking soda, cinnamon, ginger, cloves, and allspice.', 'Set aside.', "', 'In a large bowl, whisk together the agave nectar, maple syrup, applesauce, safflower oil, vanilla, and raisins.", 'Beat in the flour mixture alternately with the dry ingredients, beginning and ending with flour mixture.', 'Pour batter into prepared pan.', "', 'Bake in the preheated oven for 50 to 60 minutes, or until a toothpick inserted into the center of the cake comes out clean.", "Let cool in pan for 10 minutes, then turn out onto a wire rack and cool completely.'"]


TEST 2: no measurements + many ingredients
Text:   brown sugar, raisins, water, shortening, baking soda, salt, ground cinnamon, nutmeg, cloves, flour
Output:  tensor([[    0,  2233,    10,  2184, 13016,     7,    77, 25727, 17031,  7943,
            10,     3,    31,   345, 22777,  4836,    12, 10239,  4526,   377,
          4077,  3072,  4526,   205,   137,  3796, 14608,    11,  7055,     3,
             9,   668,   226,  2368,  5913,  2131,     5,   180,    99,    17,
           544,     8,  7055,     6,  4216,  2656,     6, 31078,     6,   387,
             6,   710,    35,    53,     6,  6506, 12495,     6,  3136,     6,
         18684,     6,     3,  4796,   526,   122,    11, 27577,     7,     5,
          2821,  5915,     5,    31,     6,     3,    31,  1570,     3,     9,
           508,  3047,     6,  3022,   544,     8,  7055,     6,  4216,  2656,
             6, 31078,     6,   387,     6,    11, 27577,     7,   552,   659,
            11, 25155,     5, 14117,    16,     8,  7055,  4989,     5,  1474,
         15839,   139,  2657,  2131,     5,    31,     6,     3,    31,   279,
             9,  1050,    16,     8,   554,    88,   920,  4836,    21,   604,
            12,  3097,   676,     6,    42,   552,     3,     9,  6290, 17967,
             3, 19435,   139,     8,  1530,    13,     8,  4340,   639,    91,
          1349,     5,  1563,  1633,    16,  2131,    21,   335,   676,     6,
           258,   919,    91,  2400,     3,     9,  4107,  7782,    11,  1633,
          1551,     5,    31,     1]])


Decoded output:  title: Apple Raisin Spice Cake directions: 'Preheat oven to 350 degrees F (175 degrees C). Grease and flour a 9x13 inch pan. Sift together the flour, brown sugar, raisins, water, shortening, baking soda, salt, cinnamon, nutmeg and cloves. Set aside.', 'In a large bowl, cream together the flour, brown sugar, raisins, water, and cloves until light and fluffy. Beat in the flour mixture. Pour batter into prepared pan.', 'Bake in the preheated oven for 30 to 35 minutes, or until a toothpick inserted into the center of the cake comes out clean. Let cool in pan for 10 minutes, then turn out onto a wire rack and cool completely.'


Prediction:  ["title: Apple Raisin Spice Cake directions: 'Preheat oven to 350 degrees F (175 degrees C).", 'Grease and flour a 9x13 inch pan.', 'Sift together the flour, brown sugar, raisins, water, shortening, baking soda, salt, cinnamon, nutmeg and cloves.', 'Set aside.', "', 'In a large bowl, cream together the flour, brown sugar, raisins, water, and cloves until light and fluffy.", 'Beat in the flour mixture.', 'Pour batter into prepared pan.', "', 'Bake in the preheated oven for 30 to 35 minutes, or until a toothpick inserted into the center of the cake comes out clean.", "Let cool in pan for 10 minutes, then turn out onto a wire rack and cool completely.'"]


TEST 3: no measurements + few ingredients
Text:  flour, yeast, apple, banana
Output:  tensor([[    0,  2233,    10,  5185,   152,     9, 17031,  2466,  7943,    10,
             3,    31,   345, 22777,  4836,    12, 10239,  4526,   377,  4077,
          3072,  4526,   205,   137,  3796, 14608,    11,  7055,     3,     9,
           335,  5913,  6100,    26,    17,  2131,     5,    31,     6,     3,
            31,  1570,     3,     9,   508,  3047,     6,  2153,  7055,     6,
         17937,     6,  8947,    11, 13634,     5,  7382,   168,    11,   171,
           139,  2657,  2131,     5,    31,     6,     3,    31,   279,     9,
          1050,    44, 10239,  4526,   377,  4077,  3072,  4526,   205,    61,
            21,   604,    12,  3097,   676,     6,    42,   552,  6290, 17967,
             3, 19435,   139,  1530,    13,  4340,   639,    91,  1349,     5,
            31,     1]])


Decoded output:  title: Banana Cake II directions: 'Preheat oven to 350 degrees F (175 degrees C). Grease and flour a 10 inch Bundt pan.', 'In a large bowl, mix flour, yeast, apple and banana. Mix well and pour into prepared pan.', 'Bake at 350 degrees F (175 degrees C) for 30 to 35 minutes, or until toothpick inserted into center of cake comes out clean.'


Prediction:  ["title: Banana Cake II directions: 'Preheat oven to 350 degrees F (175 degrees C).", 'Grease and flour a 10 inch Bundt pan.', "', 'In a large bowl, mix flour, yeast, apple and banana.", 'Mix well and pour into prepared pan.', "', 'Bake at 350 degrees F (175 degrees C) for 30 to 35 minutes, or until toothpick inserted into center of cake comes out clean.'"]



7/3/2024: 
- Focus on refining
- Question: how does it fare with similar apps out there? 

Object Detection: 
- Lit review for whats out there and how it was modified for the current problem to show contribution.
- Arugments: 
    - Dataset
    - implementation    
        - Did you focus on other parameters? 
        - Parameters have to start form somewhere (give lit review) - Models, layers etc
        - How was it fine tuned 
- Considered the use of VIT- visual transformer but it was only introduced late last year

Text Detection: 
- Write function to make TrOCR work or show weakness and prove it

Chatbot: 
- Find comparison of expressions or syntax:
- Measure relevance 
- Try language models

Recipe Recommendation: 
- Approaches and lit review for parameters 
- Summarise why it doenst work 
- Relevance 

Final Report: 
- For comparing, top 3 and narrow down

- Introduction: 
    - Whats out there
    - Narrow down dataset baking
- Lit Review:
    - Detail
    - Compare approaches 
- Implementations 
    - Implementations that didnt work
- Results: 
    - Decision tree for chatbot
    - the one chosen from lit reviews
    

To-Do:
chatbot: 
- tf-idf tokenizer
- naive bayes classificaiton 


Object detection: 
- resnet50
- mobilenet etc

text detection: 
confuction matrix as a parameter


    1. Progress Bar
        - make progress bar with text on current step
        - do not make loading screen 
        - freeze buttons during progression to prevent excessive button pressing DONE

    2. Split detect mode
        - Save object mode and text mode preview images DONE
        - Set a preview image for object and text mode

    3. Info button to provide details on how to use

    4. Chatbot
        - Train chatbot to handle follow up questions  
        - ingredient list: print ingredient in a list DONE
            a
            b
            c
        - print directions in numerical DONE
            1. 
            2. 
            3. 

    5. Final Report 
        - Read interim feedback

    6. Refine models

    7. Keyword input 

Tissa: 22/2/24
    1. Upload image submit: 
        - do not use loading screen, use progress bar
        - freeze buttons during progression
        - make combine results and generate recipe happen only once, not for everyme object detectio nand text deteciton occur

    1.1 Save images uploaded to object and text mode DONE

    2. Use sample image as a preview example for the image uploader: 
        - use 1 image upload bin and a button to swap in and out. 

    3. Info button to provide details on how to use

    4. Chatbot: DONE
        - ingredients list: print ingredients in a list 
        - A
        - B
        - C

        - Directions: print numerical DONE
        - 1.
        - 2.
        - 3.

    5. Todo: 
        - Start writing final report DONE
        - refine 3 models
        - train chatbot to handle follow uploads
        - handle keyword input

    6. Final report: 
        - read interim feadback

=======================================================================================
High Priority: 
1. Rewrite aims and goals 
2. Compete BERT and GPT implementations

Tissa: 1/2/24
    1. Object Detection ResNet50 model issues: 
        - Test on public dataset to compare results and find the issues
        Update: Successfully trained a ResNet50 model - 8/2/24

    2. Text Detection: 
        - Must justify why come to tesseract
        - What ocr are out there - list top 3 based on articles and narrowed it to tessearct based on results .
        - Results showed me tesseract is better. 

    3. Recipe Recommendation: 
        - Argument wise: why is yours different from the others out there?
        - other ones are different how. 
        - Literature review: finding a flaw that contributes to why we do this? 

    4. Can the model differentiate sugar and salt 
        - Update: no it cannot - 8/2/24

    5. Language Model Approach: 
        - Get results by the end of the month.  
        - Literature review supporting this approach.

    6. Use of SEGP: 
        - Cite my segp final report 
    This method was originally presented here but is being used here with modifications 
    In what way modifications 

    7. No need database: 
        - future work for personalised exper 


===========================================================================
Activate Server:
cd server
venv/Scripts/activate
activate

=======================================================================================
Object Detection:
Proposed apporach for object detection: 
Backwards filtering: Find images for whichever ingredients possible 
(Many ingredients simply cannot be found or do not have adequent amount of available images)
- Target to be roughly 60 classes. 

Missing / Cannot find images for certain ingredients.
Approach 1: Remove from recipe (may remove a lot)
Approach 2: Use text detection on labels
Approach 3: Generalise, example all types of flour under flour. (May cause issues recipe matching but can be fixed in NLP)
Approach 4: Find ingredients at supermarket and take pictures.

Object detection allocation:
The training part comprises 631 images (70%), 
the validation part comprises 179 images (20%), 
the testing part comprises 95 images (10%). 

The YOLOv5 model is trained on the Q-100 food ingredient dataset for 100 epochs, and it takes 9.5 h to complete

source: https://www.mdpi.com/1424-8220/22/21/8290

8/1/23
Priority (Baking Essentials): 
Salt, Sugar, Butter, Milk, Flour, Yeast, Oil

Secondary: 
Nuts, Fruits, Vegetables, Cheeses

Tertiary: 
Jams, Creams, Sauces, Beverages

Abandon: 
Baking Soda/Powder, Cake mix, Extract/Essence
- Solution: Switch to Text Detection

16/1/23
Classification for packages and bottles? 
Consideration: 
- Apple Sauce
- Apple Juice
- Beer
- Cookies
- Chocolate Milk
- Coffee
 -- cappuccino
 -- espresso
 -- white coffee
 -- black coffee
- Coconut
- Honey
- Ice Cream
- Jams
- Mango
- Mayonnaise
- Parmesan
- Parsley
- Pomegranate
- Red wine
- Vegetable Oil
- Water
- Yeast

Food and Vegetable Image Recognition: 
1. Apple
2. Banana
3. Bell Pepper
4. Carrot
5. Corn
6. Garlic
7. Ginger
8. Grapes
9. Kiwi
10. Lemon
11. Lettuce
12. Mango
13. Onion
14. Orange
15. Paprika
16. Pear
17. Pineapple
18. Pomegranate
19. Potato
20. Sweet Potato
21. Tomato
22. Turnip
23. Watermelon

23/1/23
66 classes being trained. 
Accuracy capped at 70%
Approaches: 
1. Change model
2. Change layers
3. Change epochs

30/1/23
layer explanations 
Source: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10381218/

1/2/23
Object Detection ResNet50 model issues: 
    - Test on public dataset to compare results and find the issues
    - Result: Same dataset performed ok when performed on "categorical" class mode instead of "raw"

4/2/23
- New implementation has high accuracy and low loss but higher val accuracy then accuracy
- Issue may lie in dataset formation. Therefore, use dataset split to get perfect 80 20 ratio. 
- Functional with high accuracy and low loss. 

- Move on to refinement. Flour cannot be differentiate with salt etc

5/2/23
- Double down Resnet50: Fine way to implement window sliding.
- Yolov5: complete dataset
=========================================================================================
Text detection:
TR-OCR - backed by literature 
Tesseract - easy to implement
Requires more training, try to test with conjuction with object detection to output 
Ingredients Detected:
xxx
xxx

Labels Detected:
xxx
xxx

IAM Test Dataset download: 
https://layoutlm.blob.core.windows.net/trocr/dataset/IAM.tar.gz?sv=2022-11-02&ss=b&srt=o&sp=r&se=2033-06-08T16:48:15Z&st=2023-06-08T08:48:15Z&spr=https&sig=a9VXrihTzbWyVfaIDlIT1Z0FoR1073VB0RLQUMuudD4%3D
Extract: tar -xzf IAM.tar.gz


8/1/23
Switch to Tesseract-OCR
- TR-OCR has a weakness that allows it to only read one line. Not ideal for this case. 
- Image processing (cropping/ flipping/ color change)


1/2/23
Must justify why come to tesseract
What ocr are out there - list top 3 based on articles and come to the conclusion of tesseract.
==========================================================================================
Recipe Matching:

Source: https://ijrpr.com/uploads/V4ISSUE5/IJRPR13651.pdf
1. Random Forest
2. K-Nearest Neighbors
3. Support Vector Machines 
4. Decision Tree
5. GPT-2
6. K-Means Clustering

Source: https://nycdatascience.com/blog/student-works/capstone/recipe-recommendation/
1. K-Means Clustering
2. Latent Dirichlet Allocation (LDA)
3. Top2Vec with Doc2Vec / Word2Vec
4. BERTopic
5. Correlation Explanation (CorEx)
Best: CorEx, Top2Vec 
Worst: BERTopic 

Approaches: 
1. CorEx
2. Top2Vec with Doc2Vec / Word2Vec
3. KNN


27/1/23
Saving recipe recommendation training code as pynb file because converting to python file causes issues.
Dimension mismatch, etc.. causes output to be different from pynb file. 
===============
Natural Language Processing: 
https://github.com/shubhamchouksey/NLP_Recipes?tab=readme-ov-file

https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9094119

==========================================================================================
NLP:
1. Primary Purpose: 
Output recipe recommendations

2. Secondary Purpose:
Handle Followup questions

3. Framework: 
Most Popular: Rasa, Chatterbox
Chatterbox not compatible with python 3.7 > 
pip install pyyaml==5.1.2 --user
pip install chatterbot==1.0.2 --user

Chatbot: 
29/1/23
Intent add ons: 
Date and Time
Weather

Irfan: 
train model on prompt
prompt based on key ingredients
pretrained language model on content / recipes

BART classifer
- classify ingredients
- classify into title
- title output

GPT-3 explanator
- tiile input here
- output directions


13/2/23
Vegan: Cakes made without any animal products, including eggs, dairy, or honey.
Gluten-Free: Cakes that do not contain gluten, suitable for individuals with gluten intolerance or celiac disease.
Chocolate: Cakes that prominently feature chocolate as a primary ingredient.
Nut-Free: Cakes made without nuts or nut-based ingredients to accommodate individuals with nut allergies.
Fruit: Cakes that include fruits either as a topping, filling, or incorporated into the batter.
Classic: Traditional cake recipes that are well-known and commonly made, such as vanilla, chocolate, or marble cakes.
Layer Cake: Cakes composed of multiple layers with frosting or filling between each layer.
Cupcake: Small cakes baked in individual portions, typically frosted and decorated.
Special Occasion: Cakes designed for specific events or celebrations, such as birthdays, weddings, or holidays.
Decadent: Indulgent cakes known for their richness and luxurious ingredients, often featuring high-quality chocolate, cream, or butter.
Healthy: Cakes made with alternative ingredients to reduce sugar or fat content, such as using applesauce or yogurt as a substitute.
Seasonal: Cakes that incorporate seasonal flavors or ingredients, such as pumpkin spice for fall or citrus for summer.
Cheesecake: Cakes made with a base of cream cheese and often featuring a crumb crust.
Muffins: Cake-like baked goods that are typically less sweet and denser than traditional cakes, often enjoyed for breakfast or brunch.
Decorated: Elaborately decorated cakes with intricate designs or fondant decorations, often used for special events or competitions.
=======================================
Frontend

======================================
Flask
PS C:\Users\yewji\FYP_20297501> pip install flask
Requirement already satisfied: Werkzeug>=2.0 in c:\users\yewji\appdata\local\programs\python\python39\lib\site-packages (from flask) (2.0.1)
Requirement already satisfied: itsdangerous>=2.0 in c:\users\yewji\appdata\local\programs\python\python39\lib\site-packages (from flask) (2.0.1)
Requirement already satisfied: Jinja2>=3.0 in c:\users\yewji\appdata\local\programs\python\python39\lib\site-packages (from flask) (3.0.1)
Requirement already satisfied: click>=7.1.2 in c:\users\yewji\appdata\local\programs\python\python39\lib\site-packages (from flask) (8.1.7)
Requirement already satisfied: colorama in c:\users\yewji\appdata\local\programs\python\python39\lib\site-packages (from click>=7.1.2->flask) (0.4.6)
Requirement already satisfied: MarkupSafe>=2.0 in c:\users\yewji\appdata\local\programs\python\python39\lib\site-packages (from Jinja2>=3.0->flask) (2.0.1)
WARNING: Ignoring invalid distribution -rotobuf (c:\users\yewji\appdata\local\programs\python\python39\lib\site-packages)
WARNING: Ignoring invalid distribution -rotobuf (c:\users\yewji\appdata\local\programs\python\python39\lib\site-packages)
WARNING: Ignoring invalid distribution -rotobuf (c:\users\yewji\appdata\local\programs\python\python39\lib\site-packages)
WARNING: Ignoring invalid distribution -rotobuf (c:\users\yewji\appdata\local\programs\python\python39\lib\site-packages)

[notice] A new release of pip available: 22.3.1 -> 23.3.2
[notice] To update, run: C:\Users\yewji\AppData\Local\Programs\Python\Python39\python.exe -m pip install --upgrade pip
PS C:\Users\yewji\FYP_20297501> cd server
PS C:\Users\yewji\FYP_20297501\server> venv/Scripts/activate
(venv) PS C:\Users\yewji\FYP_20297501\server> pip install flask
Fatal error in launcher: Unable to create process using '"C:\Users\yewji\FYP_20297501\server\Scripts\python.exe"  "C:\Users\yewji\FYP_20297501\server\venv\Scripts\pip.exe" install flask': The system cannot 
find the file specified.

solution: 
anaconda download ssl certain
worked when: run pip install flask and others using administrator cmd 
=================================================================================